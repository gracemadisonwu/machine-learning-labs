{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BNgZuPy0qJD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zs3GpMYq0qJF"
      },
      "outputs": [],
      "source": [
        "# making a Logistic Regression modeler from scratch using Numpy and linear algebra methods\n",
        "class LogisticRegressionScratch(object):\n",
        "\n",
        "    def __init__(self, tolerance = 10**-8, max_iterations = 20):\n",
        "\n",
        "        self.tolerance = tolerance\n",
        "        self.max_iterations = max_iterations\n",
        "        self.weights_array = None # holds current weights and intercept (intercept is at the last position)\n",
        "        self.prior_w = None # holds previous weights and intercept (intercept is at the last position)\n",
        "\n",
        "        # once we are done training, these variables will hold the\n",
        "        # final values for the weights and intercept\n",
        "        self.weights = None\n",
        "        self.intercept = None\n",
        "\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        '''\n",
        "        Compute probabilities using the inverse logit\n",
        "        - Inputs: The Nx(K+1) matrix with intercept column X\n",
        "        - Outputs: Vector of probabilities of length N\n",
        "        '''\n",
        "\n",
        "        XW = np.dot(X, self.weights_array)\n",
        "        P = 1 / (1+np.exp(-XW))\n",
        "        return P\n",
        "\n",
        "    def compute_gradient(self, X, Y, P):\n",
        "        '''\n",
        "        Computes the gradient vector\n",
        "        -Inputs:\n",
        "            - The Nx(K+1) matrix with intercept column X\n",
        "            - Nx1 vector y (label)\n",
        "            - Nx1 vector of predictions P\n",
        "        -Outputs: 1x(K+1) vector of gradients\n",
        "        '''\n",
        "\n",
        "        G = -np.dot((Y - P), X)\n",
        "        return G\n",
        "\n",
        "    def compute_hessian(self, X, P):\n",
        "        '''\n",
        "        computes the Hessian matrix\n",
        "        -inputs:\n",
        "            - Nx(K+1) matrix X\n",
        "            - Nx1 vector of predictions P\n",
        "        -outputs:\n",
        "            - KxK Hessian matrix H=X^T * Diag(Q) * X\n",
        "        '''\n",
        "\n",
        "        Q = P*(1-P)\n",
        "        XQ = X.T * Q\n",
        "        H = np.dot(XQ,X)\n",
        "        return H\n",
        "\n",
        "\n",
        "    def update_weights(self, X, y):\n",
        "        '''\n",
        "        Updates existing weight vector\n",
        "        -Inputs:\n",
        "            -Nx(Kx1) matrix X\n",
        "            -Nx1 vector y\n",
        "        -Calls predict_proba, compute_gradient and compute_hessian and uses the\n",
        "        return values to update the weights array\n",
        "        '''\n",
        "\n",
        "        P = self.predict_proba(X)\n",
        "        G = self.compute_gradient(X, y, P)\n",
        "        H = self.compute_hessian(X, P)\n",
        "        self.prior_w = self.weights_array\n",
        "        H_inv = np.linalg.inv(H)\n",
        "        self.weights_array = self.prior_w - np.dot(H_inv, G)\n",
        "\n",
        "\n",
        "    def check_stop(self):\n",
        "        '''\n",
        "        check to see if euclidean distance between old and new weights (normalized)\n",
        "        is less than the tolerance\n",
        "\n",
        "        returns: True or False on whether stopping criteria is met\n",
        "        '''\n",
        "\n",
        "        w_old_norm = self.prior_w / np.linalg.norm(self.prior_w)\n",
        "        w_new_norm = self.weights_array / np.linalg.norm(self.weights_array)\n",
        "        diff = w_old_norm - w_new_norm\n",
        "        distance = (np.dot(diff, diff))**0.5\n",
        "        stop = distance < self.tolerance\n",
        "        return stop\n",
        "\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        '''\n",
        "        X is the Nx(K-1) data matrix\n",
        "        Y is the labels, using {0,1} coding\n",
        "        '''\n",
        "\n",
        "        #set initial weights - add an extra dimension for the intercept\n",
        "        self.weights_array = np.zeros(X.shape[1] + 1)\n",
        "\n",
        "        #Initialize the slope parameter to log(base rate/(1-base rate))\n",
        "        self.weights_array[-1] = np.log(y.mean() / (1-y.mean()))\n",
        "\n",
        "        #create a new X matrix that includes a column of ones for the intercept\n",
        "        X_int = np.hstack((X, np.ones((X.shape[0],1))))\n",
        "\n",
        "        for i in range(self.max_iterations):\n",
        "            self.update_weights(X_int, y)\n",
        "\n",
        "            # check whether we should\n",
        "            stop = self.check_stop()\n",
        "            if stop:\n",
        "                # since we are stopping, lets save the final weights and intercept\n",
        "                self.set_final_weights()\n",
        "                self.set_final_intercept()\n",
        "                break\n",
        "\n",
        "\n",
        "    def set_final_weights(self):\n",
        "        self.weights = self.weights_array[0:-1]\n",
        "\n",
        "    def set_final_intercept(self):\n",
        "        self.intercept = self.weights_array[-1]\n",
        "\n",
        "    def get_weights(self):\n",
        "        return self.weights\n",
        "\n",
        "    def get_intercept(self):\n",
        "        return self.intercept\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLFETWR80qJG"
      },
      "outputs": [],
      "source": [
        "filename = os.path.join(os.getcwd(), \"data\", \"airbnbData_train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjTYh5oo0qJG"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kerbJGSS0qJH",
        "outputId": "55043dd8-b8bb-4838-96f9-01b7f5a50c7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['review_scores_rating',\n",
              " 'review_scores_cleanliness',\n",
              " 'review_scores_checkin',\n",
              " 'review_scores_communication',\n",
              " 'review_scores_value',\n",
              " 'host_response_rate',\n",
              " 'host_acceptance_rate']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_list = ['review_scores_rating','review_scores_cleanliness','review_scores_checkin','review_scores_communication','review_scores_value','host_response_rate','host_acceptance_rate']\n",
        "feature_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPXLiBQH0qJH"
      },
      "outputs": [],
      "source": [
        "X = df[feature_list]\n",
        "y = df['host_is_superhost']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0M7q_cF0qJI"
      },
      "outputs": [],
      "source": [
        "lr = LogisticRegressionScratch()\n",
        "lr.fit(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3EDIsxW0qJI",
        "outputId": "5681ac81-bf63-4748-a6c8-5ddfbb0bf442"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The fitted weights and intercept are:\n",
            "[ 0.56690005  0.492255    0.201587    0.25551467 -0.00590516  1.71592957\n",
            "  0.26478817] -1.829062262272181\n"
          ]
        }
      ],
      "source": [
        "print('The fitted weights and intercept are:')\n",
        "print(lr.get_weights(), lr.get_intercept())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iW7YAMVj0qJI",
        "outputId": "8e155866-58a1-4809-caec-72f7f4d9e3f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(C=10000000000, class_weight=None, dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr_sk = LogisticRegression(C=10**10)\n",
        "lr_sk.fit(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzNSw-OQ0qJI",
        "outputId": "8fb56ce7-073d-4b99-ccab-10fcd1a27b5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The fitted weights and intercept with sklearn are:\n",
            "[[ 0.56691547  0.49224905  0.20150113  0.25563246 -0.005929    1.71592022\n",
            "   0.26479199]] [-1.82906726]\n"
          ]
        }
      ],
      "source": [
        "print('The fitted weights and intercept with sklearn are:')\n",
        "print(lr_sk.coef_, lr_sk.intercept_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6zpzSyU0qJJ",
        "outputId": "15ea0e72-3a99-493d-f095-9b2ff1149697"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28.1 ms ± 8.77 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit(lr.fit(X,y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaCjRvSR0qJJ",
        "outputId": "f8d26397-71e7-45d0-c8ac-9bf836b79719"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "90.8 ms ± 5.75 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit(lr_sk.fit(X,y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0p8skWol0qJ3"
      },
      "outputs": [],
      "source": [
        "# It seems that our logistic regression model is faster than the SciKit one."
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}